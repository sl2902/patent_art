{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13039976,"sourceType":"datasetVersion","datasetId":8257192},{"sourceId":13047194,"sourceType":"datasetVersion","datasetId":8261901},{"sourceId":13047204,"sourceType":"datasetVersion","datasetId":8261906}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport json\nfrom kaggle_secrets import UserSecretsClient\nfrom google.oauth2 import service_account\nos.chdir('/kaggle/input/patent-art')\nsys.path.append('/kaggle/input/patent-art')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T12:54:48.779884Z","iopub.execute_input":"2025-09-13T12:54:48.780719Z","iopub.status.idle":"2025-09-13T12:54:49.180823Z","shell.execute_reply.started":"2025-09-13T12:54:48.780686Z","shell.execute_reply":"2025-09-13T12:54:49.179609Z"},"_kg_hide-input":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2539925291.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle_secrets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice_account\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/patent-art'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/patent-art'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/patent-art'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/patent-art'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"!uv pip install --no-cache-dir -r requirements-kaggle.txt &> /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:19:34.499141Z","iopub.execute_input":"2025-09-12T15:19:34.499761Z","iopub.status.idle":"2025-09-12T15:19:36.195595Z","shell.execute_reply.started":"2025-09-12T15:19:34.499725Z","shell.execute_reply":"2025-09-12T15:19:36.194025Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_credentials(secret_name: str = \"gcp_service_account\")  -> service_account.Credentials:\n    \"\"\"Fetch GCP Credentials\"\"\"\n    user_secrets =  UserSecretsClient()\n    service_account_json = user_secrets.get_secret(secret_name)\n\n    with open(\"/tmp/service_account.json\", \"w\") as f:\n        f.write(service_account_json)\n    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/tmp/service_account.json\"\n    credentials_info = json.loads(service_account_json)\n    credentials = service_account.Credentials.from_service_account_info(credentials_info)\n\n\n    gcp_secrets = json.loads(user_secrets.get_secret(secret_name))\n\n\n    os.environ[\"project_id\"] = gcp_secrets[\"project_id\"]\n    os.environ[\"dataset_id\"] = user_secrets.get_secret(\"dataset_id\") \n    os.environ[\"publication_table\"] = user_secrets.get_secret(\"publication_table\")\n    os.environ[\"small_model_id\"] = user_secrets.get_secret(\"small_model_id\")\n    os.environ[\"embedding_table\"] = user_secrets.get_secret(\"embedding_table\")\n    os.environ[\"service_account_path\"] = \"/tmp/service_account.json\"\n    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/tmp/service_account.json\"\n\n    os.environ[\"hf_token\"] = user_secrets.get_secret('hf_token') \n\n    return user_secrets, credentials\n\nuser_secrets, credentials = get_credentials()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:20:08.301920Z","iopub.execute_input":"2025-09-12T15:20:08.302245Z","iopub.status.idle":"2025-09-12T15:20:09.193006Z","shell.execute_reply.started":"2025-09-12T15:20:08.302222Z","shell.execute_reply":"2025-09-12T15:20:09.192124Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from src.kaggle.patent_dashboard_chart_functions import (\n    create_patent_dashboard_demo\n)\nfrom run_patent_search_pipeline import (\n    run_semantic_search_pipeline,\n)\nfrom src.kaggle.kaggle_patent_search_demo import(\n    demo_search_interface\n)\nfrom src.kaggle.kaggle_patent_chart_metrics import(\n    create_latency_visualization,\n    create_bigquery_visualization,\n    create_discoverability_visualization,\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:20:09.524350Z","iopub.execute_input":"2025-09-12T15:20:09.525407Z","iopub.status.idle":"2025-09-12T15:21:18.343106Z","shell.execute_reply.started":"2025-09-12T15:20:09.525375Z","shell.execute_reply":"2025-09-12T15:21:18.341540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>Patent Intelligence: Semantic Search for Innovation Discovery</h1>","metadata":{"execution":{"iopub.status.busy":"2025-09-09T15:46:47.206447Z","iopub.execute_input":"2025-09-09T15:46:47.207315Z","iopub.status.idle":"2025-09-09T15:46:47.221188Z","shell.execute_reply.started":"2025-09-09T15:46:47.207277Z","shell.execute_reply":"2025-09-09T15:46:47.219820Z"}}},{"cell_type":"markdown","source":"## Problem Statement\n\nThe exponential growth in global patent publication (3.6M applications in 2023, representing 2.7% growth year-over-year [WIPO 2024](https://www.wipo.int/edocs/pubdocs/en/wipo-pub-943-2024-en-wipo-ip-facts-and-figures-2024.pdf). 68.7% of global patent aplications in 2023 originated from China (WIPO 2024) displaying China's dominance. Globally, patent filings increased by 18.1% between 2019-2023 indicating accelerating innovation; this creates significant challenges for innovation research and competitive intelligence. Our analysis of Google's patent publication corpus reveals that English-language patent publication peaked in 2020-2021, declined 5.6% through 2023, with partial recovery in 2024.<br>\nTraditional keyword-based patent search systems fail to capture semantic relationships between technologies, forcing researchers to spend excessive time on manual review and potentially missing relevant prior art. With 2.9M English-language patents from our 2024 dataset(14.4GB) representing the first half of the year of global innovation output, there is a clear need for semantic search capabilities that can understand technological concepts beyond surface-level keyword understanding.","metadata":{}},{"cell_type":"markdown","source":"## Architectural Diagram & Decisions\n\n**Hybrid Processing Strategy:** The combination of performance constraints and platform limitations led to a multi-stage architecture:\n1. Offline Bulk Processing: Kaggle GPU for embedding generation (6.5 hours for 2.9M patents)\n2. Real-time Query Processing: CPU-based query embeddings (~500ms per query)\n3. Production-Ready Optimization: BigQuery partitioning and clustering for cost efficiency\n4. Edition-Aware Design: Index-ready architecture that can utilize vector indexing when deployed on Enterprise+ tiers\n5. Streamlit Cloud Demo - Easily shareable interactive dashboard enabling non-technical stakeholders to experience semantic patent discovery with explainability, leveraging real-time BigQuery AI integration for enterprise adoption validation","metadata":{}},{"cell_type":"markdown","source":"## Data Pipeline Overview\n\nThis notebook demonstrates the core BigQuery AI semantic search functionality. \nThe complete pipeline involved:\n1. Raw dataset filtering (2.6TB → 49M patents → 2.9M subset)\n2. Embedding generation (6.5 hours on Kaggle GPU)\n3. BigQuery AI vector search implementation (shown below)\n\nDue to compute costs, the preprocessing steps were executed offline. Check the <a id=\"Assets\"></a>[Repo](#Assets) for source code","metadata":{}},{"cell_type":"markdown","source":"## Static Demo: Semantic Patent Search with Explainability\n\n**Text Query Mode:** Users enter natural language descriptions of technical concepts or inventions. The system provides configurable search parameters:\n\n- **Date Range Filter:** Limited to our 2024 dataset (January-June 2024, 2.9M patents)\n- **Results Slider:** Select top-K similar patents (1-20 results)\n\n**Patent Number Mode:** Direct lookup by entering specific patent publication numbers (one per line). If multiple patent numbers\nare provided, then the system computes the average value of the embeddings to return similar patents\n**Search Results & Relevance Scoring:**\nUpon executing a search, the system returns ranked results with comprehensive metadata:\n\n- Patent title and publication details (number, date, country)\n-  **Document Relevance Score:** Semantic similarity percentage\n\n    - **High Relevance:** >65% (strong conceptual match)\n    - **Moderate Relevance:** 50-65% (related concepts)\n    - **Low Relevance:** <50% (weak conceptual connection)\n\n\n- Complete patent abstract for context\n\n**Input Validation & Quality Control:**\nThe interface implements query sanitization and validation to optimize database performance. While most invalid queries are filtered, some may pass validation but return low-relevance results due to poor semantic matching.<br>\n**Explainability Feature:**\nOur advanced explainability component provides transparency into search results by identifying the most semantically similar sentences between the user query and patent content. This feature returns up to 3 explanatory results ranked by sentence-level similarity scores, enabling users to understand why specific patents were recommended.\nThis approach demonstrates BigQuery AI's capability to provide not just semantic search results, but interpretable insights into the matching process.\n\n","metadata":{}},{"cell_type":"code","source":"demo_search_interface()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:24:23.340599Z","iopub.execute_input":"2025-09-12T15:24:23.340915Z","iopub.status.idle":"2025-09-12T15:24:23.385407Z","shell.execute_reply.started":"2025-09-12T15:24:23.340895Z","shell.execute_reply":"2025-09-12T15:24:23.382829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## BigQuery AI Semantic Search: Technical Implementation and Scalability Analysis\n\nThe following sections present comprehensive performance analysis of our BigQuery AI implementation, demonstrating sub-4 second query times across 2.9M patents, 84% cost reduction and 12% time reduction through intelligent partitioning, and 98.3% unique discovery rates compared to keyword search methods.<br>\nTesting was carried out across 10 diverse technology queries avoiding caching, comparing performances between development (laptop) and cloud (Kaggle) environments. Each query returned 20 semantic results including full patent metadata (title, abstract, publication details, similarity scores), representing typical user search behavior:","metadata":{}},{"cell_type":"markdown","source":"#### Scalability Validation\n\nOur implementation demonstrates production-ready scalability across multiple dimensions:\n\n**Data Volume Scalability:**\n- Successfully processes 2.9M patents(14.4GB) with consistent performance\n- Linear cost scaling through partition pruning(84% data reduction for targeted searches)\n- Architecture supports horizontal scaling to full 49M patent corpus via month-based partitioning\n\n**Query Performance Scalability:**\n- Achieves sub-4 second vector search response times across 2.9M patents with partition pruning enabling cost-effective scaling to larger datasets\n- Consistent performance regardless of partition size (2.8-3.9 seconds for vector search operations)\n- 1-month partitioning delivers 12% performance improvement in addition to 84% cost reduction\n- Partition pruning demonstrates stable performance despite 5x variation in data volume\n\n**Cost-Efficient Scalability:**\n- Partition pruning delivers 84% reduction in bytes processed for 1-month searches\n- Production deployment cost optimization through BigQuery clustering strategies\n- Enterprise+ tier compatibility enables vector indexing for further performance gains\n\n**Concurrent Processing Scalability:**\n- Batch processing architecture handles 5,000-record embedding generation efficiently\n- Multi-environment deployment validation (Kaggle GPU vs local processing)\n- Separation of offline bulk processing (embeddings) from real-time queries enables concurrent user support\n","metadata":{}},{"cell_type":"code","source":"create_bigquery_visualization()","metadata":{"execution":{"iopub.status.busy":"2025-09-12T15:27:24.469247Z","iopub.execute_input":"2025-09-12T15:27:24.469604Z","iopub.status.idle":"2025-09-12T15:27:28.241178Z","shell.execute_reply.started":"2025-09-12T15:27:24.469578Z","shell.execute_reply":"2025-09-12T15:27:28.240141Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Performance Testing Results\n\n**Latency Measurements:** **Environment Comparison**\n\nCore Vector Search Performance<br>\n**Kaggle Environment:**\n\n- Mean latency: 3.0 seconds\n- Median latency: 2.9 seconds\n- 90th percentile: 3.2 seconds\n- Range: 2.5s - 4.2s\n\n**Laptop Environment:**\n\n- Mean latency: 4.5 seconds\n- Median latency: 4.2 seconds\n- 90th percentile: 4.9 seconds\n- Range: 3.9s - 7.2s\n\nComplete Pipeline Performance (with Explainability)<br>\n**Kaggle Environment:**\n\n- Mean latency: 5.2 seconds\n- Median latency: 5.0 seconds\n- 90th percentile: 5.5 seconds\n- Range: 4.2s - 6.7s\n\n**Laptop Environment:**\n\n- Mean latency: 12.9 seconds\n- Median latency: 11.6 seconds\n- 90th percentile: 15.2 seconds\n- Range: 9.4s - 18.7s\n\nKey Performance Insights\n\n**Environment Impact:** Kaggle environment shows 33% faster vector search and 60% faster complete pipeline performance, highlighting the benefits of cloud-native deployment proximity to BigQuery infrastructure.<br>\n**Consistency:** Kaggle environment demonstrates lower variability (std dev: 467ms vs 991ms for vector search), indicating more predictable performance characteristics for production deployment.<br>\n**Production Scalability:** Both environments successfully process semantic searches across 2.9M patents, with vector search completing in under 5 seconds across all test scenarios.","metadata":{}},{"cell_type":"code","source":"create_latency_visualization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:27:32.272721Z","iopub.execute_input":"2025-09-12T15:27:32.273101Z","iopub.status.idle":"2025-09-12T15:27:34.088513Z","shell.execute_reply.started":"2025-09-12T15:27:32.273075Z","shell.execute_reply":"2025-09-12T15:27:34.087483Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Semantic versus Keyword Search Discovery Analysis\n\n**Discovery Methodology:** Comparative analysis across 10 diverse technology queries that evaluate the discovery capabilities between BigQuery AI semantic search and traditional keyword search approaches. Semantic search uniqueness percentage represents the percentage of semantic search results that were not returned by keyword search methods. Each query was executed, to return a maximum of 30 results,  across both latop and Kaggle environments to validate consistency. <br>\nThe testing revealed significant differences in discovery capabilities between semantic and keyword search approaches.<br>\n\nNote - Without a ground truth dataset, we cannot accurately measure recall or precision\n\nSearch Performance Comparison<br>\n**Keyword Search:**\n\nAverage results per query: 18 patents\nAverage search time: 2.1 seconds (Kaggle), 3.4 seconds (laptop)\n\n**Semantic Search:**\n\nAverage results per query: 30 patents\nAverage search time: 2.7 seconds (Kaggle), 5.0 seconds (laptop)\n\n**Discovery Effectiveness:**\n**Cross-Environment Validation:** Testing across both laptop and Kaggle environments confirmed consistent discovery capabilities, with semantic search finding 295 unique patents and keyword search finding 175 unique patents in both environments:\n\n- **Total semantic results:** 300 patents (30 per query × 10 queries)\n- **Total keyword results:** 180 patents (18 per query × 10 queries)\n\n**Unique Patent Discovery:**\n\n- Semantic search discovers 295 patents not found by keyword search\n- Keyword search discovers 175 patents not found by semantic search\n- Overlap: 5 patents found by both methods\n\nSearch Method Limitations<br>\n**Keyword Search Challenges:**\n\n- Complex, multi-term technical queries often return zero results\n- Long descriptive queries (e.g., \"quantum error correction topological qubits fault tolerance\") fail to match patent terminology\nRequires exact or near-exact term matching, missing conceptually similar descriptions\n\n**Semantic Search Robustness:**\n\n- Handles complex technical descriptions effectively\n- Finds conceptually related patents even with different terminology\n- Maintains consistent result quality across diverse query complexity levels\n\n**Implications for Patent Research**\n\n**Semantic Search Superiority:** Semantic search successfully finds patents (relevant or not cannot be determined with a subject matter expert or a ground truth dataset) for all query types, including complex technical descriptions where keyword search returns zero results.<br>\n**Complementary Discovery:** The minimal overlap (5 patents) demonstrates that semantic and keyword searches access fundamentally different types of patent relevance, with semantic search providing broader conceptual coverage.<br>\n**Query Complexity Handling:** Semantic search succeeds where keyword search fails on complex technical descriptions, making it essential for sophisticated patent research workflows.\n\n","metadata":{}},{"cell_type":"code","source":"create_discoverability_visualization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:27:43.724751Z","iopub.execute_input":"2025-09-12T15:27:43.725188Z","iopub.status.idle":"2025-09-12T15:27:45.511837Z","shell.execute_reply.started":"2025-09-12T15:27:43.725152Z","shell.execute_reply":"2025-09-12T15:27:45.510722Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Technical Challenges\n\n#### Embedding Generation Performance Bottleneck\n\n\n**Initial ML.GENERATE_EMBEDDING Challenges:**\nThe biggest technical hurdle was BigQuery's native embedding generation performance. Initial attempts using ML.GENERATE_EMBEDDING on 2013-2014 patent data revealed severe limitations:\n- **Monitoring Issues:** Jobs ran for 30+ minutes with no meaningful progress tracking beyond basic UI status\n- **Performance Variability:** Batch processing showed extreme variation (7-70 minutes per 5,000 record batch)\n- **Scale Reality:** Processing 48K records (one day) took 6 hours across 10 batches, averaging 36 minutes per batch\n- **Cost-Performance Trade-off:** At ~0.45 seconds per embedding, processing 2.9M patents would require 15 days\n\n**Implementation Iterations:**\n\n**First attempt:** Single large job (2013-2014) with no progress tracking - abandoned after 30 minutes<br>\n**Second iteration:** Stored procedure with 2,000 record batches - still too slow with no visibility<br>\n**Third iteration:** Added BigQuery logging, increased to 5,000 record batches, reduced scope to 1 day (48K); the job completed in 6 hours<br>\n**Data Quality Issue:** Initial approach using LIMIT + OFFSET without ORDER BY created duplicates; resolved with ROW_NUMBER() windowing\n\n**Kaggle GPU Solution:**\nThe breakthrough came with Sentence Transformers on Kaggle GPU, processing 2.9M records (14GB) in 6.5 hours using 5,000-record batches - a dramatic improvement that made the project feasible.\n\n#### BigQuery Edition Limitations\n\n**Vector Index Discovery:**\nAfter implementing comprehensive vector indexing with 100% coverage on the 14.4GB dataset, we discovered that BigQuery Standard edition (free tier) supports VECTOR_SEARCH creation functionality but restricts vector index utilization to Enterprise+ tiers. This limitation highlights critical production planning considerations for BigQuery AI deployments.\n\n#### Development Environment Challenges\n\n**Kaggle-Specific Issues:**\n\n**Dependency conflicts:** Library version mismatches requiring minimal dependency strategies<br>\n**Repository integration:** Inconsistent import paths (/kaggle/input vs /kaggle/input/d/username) requiring defensive coding<br>\n**Workflow friction:** Manual repository re-import for each code change as the 'Link To GitHub' feature wasn't automatically picking up changes<br>\n**Environment incompatibility:** Kaggle's environment lacks Streamlit support, forcing maintenance of separate requirements.txt files divergent from the project's pyproject.toml, including charts and demos - violating software engineering principles of single source of truth and creating dual repository management overhead\n\n**Solution Strategy:** Minimize external dependencies and leverage Kaggle's pre-installed libraries to avoid conflicts, while accepting the technical debt of maintaining divergent dependency specifications.","metadata":{}},{"cell_type":"markdown","source":"## Assets\n\n1. [bigquery_ai_survey](https://www.kaggle.com/datasets/laxmsun/bigquery-ai-survey)\n2. [patent_art_github](https://github.com/sl2902/patent_art)\n3. [streamlit demo](https://patent-art.streamlit.app/)","metadata":{}},{"cell_type":"code","source":"# import generate_patent_embeddings\n# set the env variable os.environ[\"embedding_table\"] = \"table_name\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:34:19.650640Z","iopub.execute_input":"2025-09-12T15:34:19.650972Z","iopub.status.idle":"2025-09-12T15:34:19.717045Z","shell.execute_reply.started":"2025-09-12T15:34:19.650949Z","shell.execute_reply":"2025-09-12T15:34:19.715856Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python generate_patent_embeddings.py --date-start='2017-01-02' --date-end='2017-01-02' --batch-size=1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T15:40:21.427984Z","iopub.execute_input":"2025-09-12T15:40:21.428558Z","iopub.status.idle":"2025-09-12T15:40:21.434902Z","shell.execute_reply.started":"2025-09-12T15:40:21.428522Z","shell.execute_reply":"2025-09-12T15:40:21.433630Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}